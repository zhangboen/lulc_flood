{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04b0d2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee8a13ec5cb54e36a863acccdb190534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "<LAMBDA> DONE:   0%|          | 0/8619 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4311404dde9e4bcd8392cb4cf4cd4e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "<LAMBDA> DONE:   0%|          | 0/8618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.plot_utils import *\n",
    "import pickle\n",
    "import pymannkendall as mk\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "import statsmodels.api as sm\n",
    "from parallel_pandas import ParallelPandas\n",
    "ParallelPandas.initialize(n_cpu=24, split_factor=24)\n",
    "from pathlib import Path\n",
    "import json\n",
    "import statsmodels.api as sm\n",
    "from cartopy.mpl.geoaxes import GeoAxes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "dir_Qmax7 = Path('../results/run_Qmax7_onlyUrban_0506_1359_seed824956/')\n",
    "dir_Qmin7 = Path('../results/run_Qmin7_onlyUrban_0506_1357_seed220973/')\n",
    "\n",
    "Qmin7Fname = '../data/Qmin7_final_dataset_seasonal4.pkl'\n",
    "Qmax7Fname = '../data/Qmax7_final_dataset_seasonal4.pkl'\n",
    "\n",
    "par_map = pd.read_csv('../data/predictors.csv')\n",
    "\n",
    "with open(dir_Qmax7 / 'cfg.json', 'r') as fp:\n",
    "    cfg = json.load(fp)\n",
    "    \n",
    "mode = cfg['mode']\n",
    "predictors = cfg['meteo_name'] + cfg['lulc_name'] + cfg['attr_name']\n",
    "log = cfg['log']\n",
    "m3s = cfg['m3s']\n",
    "feature = cfg['feature']\n",
    "model = cfg['model']\n",
    "featureName = par_map.loc[par_map.par==feature,'name'].values[0]\n",
    "\n",
    "with open(dir_Qmin7 / 'cfg.json', 'r') as fp:\n",
    "    cfg_Qmin7 = json.load(fp)\n",
    "cfg_Qmax7 = cfg\n",
    "\n",
    "# load shap and predictors\n",
    "Qmax7_fname = dir_Qmax7 / f'{model}_{mode}_shap_values.pkl'\n",
    "shap_Qmax7 = pickle.load(open(Qmax7_fname, 'rb'))\n",
    "Qmin7_fname = dir_Qmin7 / f'{model}_{mode}_shap_values.pkl'\n",
    "shap_Qmin7 = pickle.load(open(Qmin7_fname, 'rb'))\n",
    "\n",
    "if mode == 'noLULC':\n",
    "    predictors1 = [item for item in predictors if item not in ['ImperviousSurface', 'forest', 'crop', 'grass', 'water', 'wetland']]\n",
    "elif  mode == 'onlyUrban':\n",
    "    predictors1 = [item for item in predictors if item not in ['forest', 'crop', 'grass', 'water', 'wetland']]\n",
    "\n",
    "df_shap_Qmax7 = pd.DataFrame(data = shap_Qmax7, columns = predictors1)\n",
    "df_shap_Qmin7 = pd.DataFrame(data = shap_Qmin7, columns = predictors1)\n",
    "\n",
    "par_map = pd.read_csv('../data/predictors.csv')\n",
    "\n",
    "df_Qmin7 = pd.read_pickle(cfg_Qmin7['fname'])\n",
    "df_Qmax7 = pd.read_pickle(cfg_Qmax7['fname'])\n",
    "\n",
    "df_Qmin7 = df_Qmin7[[\"ohdb_id\", \"ohdb_longitude\", \"ohdb_latitude\", 'climate_label', 'aridity', feature]]\n",
    "df_Qmax7 = df_Qmax7[[\"ohdb_id\", \"ohdb_longitude\", \"ohdb_latitude\", 'climate_label', 'aridity', feature]]\n",
    "\n",
    "df_Qmin7 = df_Qmin7.rename(columns={'ohdb_longitude':'lon','ohdb_latitude':'lat', feature:feature+'_val'})\n",
    "df_Qmax7 = df_Qmax7.rename(columns={'ohdb_longitude':'lon','ohdb_latitude':'lat', feature:feature+'_val'})\n",
    "\n",
    "df_Qmin7 = pd.concat([df_Qmin7, df_shap_Qmin7], axis = 1)\n",
    "df_Qmax7 = pd.concat([df_Qmax7, df_shap_Qmax7], axis = 1)\n",
    "\n",
    "df_Qmin7['catch'] = np.where(df_Qmin7.aridity<=0.65, 'dry', 'wet')\n",
    "df_Qmax7['catch'] = np.where(df_Qmax7.aridity<=0.65, 'dry', 'wet')\n",
    "\n",
    "df_Qmin7_ave = df_Qmin7.groupby(['ohdb_id','lon','lat','climate_label','aridity'], group_keys=False).p_apply(\n",
    "    lambda x: pd.Series(\n",
    "        [x.iloc[:,6:-1].abs().mean(0).rank(ascending=False, method='min').loc[feature], x[feature].abs().mean()],\n",
    "        index = [feature+'_rank', feature+'_shap']\n",
    "    )\n",
    ").reset_index()\n",
    "df_Qmax7_ave = df_Qmax7.groupby(['ohdb_id','lon','lat','climate_label','aridity'], group_keys=False).p_apply(\n",
    "    lambda x: pd.Series(\n",
    "        [x.iloc[:,6:-1].abs().mean(0).rank(ascending=False, method='min').loc[feature], x[feature].abs().mean()],\n",
    "        index = [feature+'_rank', feature+'_shap']\n",
    "    )\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03a51c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_shap_dependence(ax1, ax2, df_Qmin7, df_Qmax7, title = False):\n",
    "    palette0 = {'dry':'#C7B18A', 'wet':\"#65C2A5\"}\n",
    "    sns.scatterplot(df_Qmin7, x = feature+'_val', y = feature, hue = 'catch', ax = ax1, alpha = .2, palette = palette0)\n",
    "    sns.scatterplot(df_Qmax7, x = feature+'_val', y = feature, hue = 'catch', ax = ax2, alpha = .2, palette = palette0)\n",
    "\n",
    "    for i,name in enumerate(['Qmin7','Qmax7']):\n",
    "        ax = eval('ax'+str(i+1))\n",
    "        ax.set_xlabel(featureName.capitalize()+' (%)', fontsize = 9)\n",
    "        ax.set_ylabel('SHAP value', fontsize = 9)\n",
    "        sns.move_legend(ax, 'lower right', bbox_to_anchor = (.98, .02), title = None, fontsize = 9)\n",
    "        if title:\n",
    "            if i == 0:\n",
    "                ax.set_title('Dependence of low flow to '+featureName, fontsize = 9)\n",
    "            else:\n",
    "                ax.set_title('Dependence of high flow to '+featureName, fontsize = 9)\n",
    "        ax.tick_params(axis = 'both', labelsize = 9)\n",
    "\n",
    "        # estimate LOWESS\n",
    "        df0 = eval('df_'+name)\n",
    "        xvals = np.linspace(df0[feature+'_val'].min(), df0[feature+'_val'].max(), 100)\n",
    "        ps = []\n",
    "        for catch in ['dry','wet']:\n",
    "            lowess0 = sm.nonparametric.lowess(\n",
    "                df0.loc[df0.catch==catch,feature].values, \n",
    "                df0.loc[df0.catch==catch,feature+'_val'].values, \n",
    "                xvals=xvals, \n",
    "                frac=0.1, \n",
    "                return_sorted = True)   \n",
    "            p0 = ax.plot(xvals, lowess0, color = palette0[catch], lw = 1, label = catch + ' climate')\n",
    "            ps.append(p0)\n",
    "        \n",
    "        # legend\n",
    "        line1 = Line2D([], [], color=palette0['dry'], ls=\"-\", linewidth=1.5)\n",
    "        line2 = Line2D([], [], color=palette0['wet'], ls=\"-\", linewidth=1.5)\n",
    "        sc1 = plt.scatter([],[], s=15, facecolors=palette0['dry'], edgecolors=palette0['dry'])\n",
    "        sc2 = plt.scatter([],[], s=15, facecolors=palette0['wet'], edgecolors=palette0['wet'])\n",
    "        ax.legend([(sc1,line1), (sc2,line2)], ['Catchments in dry climate','Catchments in wet climate'], numpoints=1, handlelength = 1, fontsize = 9)\n",
    "\n",
    "def plot_shap_rank(ax1, ax2, df_Qmin7_ave, df_Qmax7_ave, title = False):\n",
    "    for i,name in enumerate(['Qmin7','Qmax7']):\n",
    "        ax = eval('ax'+str(i+1))\n",
    "        df = eval('df_'+name+'_ave')\n",
    "        lons = df.lon.values\n",
    "        lats = df.lat.values\n",
    "        vals = df[feature+'_rank'].values\n",
    "\n",
    "        vmin, vmax, vind = 1, shap_Qmin7.shape[1]-5, 1\n",
    "        cmap = plt.cm.RdBu_r\n",
    "        norm = mpl.colors.Normalize(vmin = vmin, vmax = vmax)\n",
    "        if title:\n",
    "            if i == 0:\n",
    "                title = f'Importance ranking of {featureName.lower()} in ML of low flows'\n",
    "            else:\n",
    "                title = f'Importance ranking of {featureName.lower()} in ML of high flows'\n",
    "        else:\n",
    "            title = None\n",
    "        label = f'SHAP ranking'\n",
    "        _, ras = plot_map(ax, lons, lats, vals, vmin, vmax, vind, cmap, title, label, norm = norm, fontSize = 9, size = 3, addHist = False)\n",
    "        # add colorbar\n",
    "        cax = ax.inset_axes([.3, .02, 0.2, .03])\n",
    "        cbar = plt.colorbar(ras, cax = cax, orientation = 'horizontal', extend = 'both')\n",
    "        cax.tick_params(labelsize = 9)\n",
    "        cax.set_title(label, size = 9, pad = 5)\n",
    "        # add boxplot to show the impact for dry (AI<1) and wet (AI>1) catchments\n",
    "        df['tmp'] = np.where(df['aridity']>0.65, 'wet', 'dry')\n",
    "\n",
    "        axin = ax.inset_axes([0.71, .05, .08, .3])\n",
    "        sns.boxplot(df, \n",
    "                    x = 'tmp', y = feature+'_rank', ax = axin, \n",
    "                    showfliers = False, width = .6, \n",
    "                    whis = [5, 95],\n",
    "                    color = '#c2dcea',\n",
    "                    showmeans = True,\n",
    "                    capprops = {'linewidth': 0},\n",
    "                    boxprops={'edgecolor': 'none'},  # No edge line\n",
    "                    meanprops={'marker': 'o',\n",
    "                        'markerfacecolor': 'white',\n",
    "                        'markeredgecolor': 'black',\n",
    "                        'markersize': '3'},\n",
    "                    medianprops={'color': 'black', 'linewidth': 1},  # Black median line\n",
    "                    whiskerprops={'color': 'black', 'linewidth': 1},  # Black whiskers\n",
    "                )\n",
    "        axin.set_facecolor('none')\n",
    "    #     axin.set_yticks([0,9])\n",
    "        axin.set_xlabel(None)\n",
    "        axin.set_ylabel(f'SHAP ranking', fontsize = 9)\n",
    "        axin.tick_params(labelsize = 9,  which='both', top = False, right = False)\n",
    "        axin.xaxis.set_minor_locator(ticker.NullLocator())\n",
    "        axin.spines[\"top\"].set_visible(False) \n",
    "        axin.spines[\"right\"].set_visible(False) \n",
    "\n",
    "def plot_ale(ax1, ax2, cfg_Qmin7, cfg_Qmax7, title = False):\n",
    "\n",
    "    model = cfg_Qmin7['model']\n",
    "    mode = cfg_Qmin7['mode']\n",
    "    feature = cfg_Qmin7['feature']\n",
    "    purpose = 'ale'\n",
    "    min_interval = 0\n",
    "    Qmin7Fname = dir_Qmin7 / f'{model}_{mode}_{purpose}_{feature}_min_interval_{min_interval:.1f}.csv'\n",
    "    Qmax7Fname = dir_Qmax7 / f'{model}_{mode}_{purpose}_{feature}_min_interval_{min_interval:.1f}.csv'\n",
    "\n",
    "    df_eff_Qmin7 = pd.read_csv(Qmin7Fname)\n",
    "    df_eff_Qmax7 = pd.read_csv(Qmax7Fname)\n",
    "\n",
    "    for i,name in enumerate(['Qmin7','Qmax7']):\n",
    "        df = eval('df_eff_'+name)\n",
    "        ax = eval('ax'+str(i+1))\n",
    "        for climate in df.climate_label.unique():\n",
    "            tmp = df.loc[df.climate_label==climate,:]\n",
    "\n",
    "            # Find common x-axis range\n",
    "            min_x = tmp['bins'].min()\n",
    "            max_x = tmp['bins'].max()\n",
    "\n",
    "            groupName = 'n_explain'\n",
    "\n",
    "            n_sample = tmp.groupby(groupName)['eff'].count().min()\n",
    "            x_range = np.linspace(min_x, max_x, n_sample)  # Adjust number of points as needed\n",
    "\n",
    "            # Interpolate each group to common x-axis\n",
    "            interpolated_data = {}\n",
    "            for group in tmp[groupName].unique():\n",
    "                group_df =tmp[tmp[groupName] == group]\n",
    "                f = interp1d(group_df['bins'], group_df['eff'], kind='linear', fill_value='extrapolate')\n",
    "                interpolated_data[group] = pd.DataFrame({'x': x_range, 'y': f(x_range), 'group': group})\n",
    "\n",
    "            # Concatenate interpolated data\n",
    "            interpolated_df = pd.concat(interpolated_data.values())\n",
    "\n",
    "            # Calculate average y values for each x\n",
    "            df_avg = interpolated_df.groupby('x').apply(\n",
    "                lambda x: pd.Series([x.y.mean(), x.y.quantile(.025), x.y.quantile(.975)], index = ['ave','low','upp'])\n",
    "            ).reset_index()\n",
    "\n",
    "            # Create the lineplot with individual lines\n",
    "            ax.plot(df_avg.x.values, df_avg.ave.values, color = palette[climate], lw = 2, label = climate, zorder = 3)\n",
    "            ax.fill_between(\n",
    "                df_avg.x.values, \n",
    "                df_avg.low.values, \n",
    "                df_avg.upp.values, \n",
    "                color = palette[climate], \n",
    "                ec = 'none',\n",
    "                alpha = .3)\n",
    "\n",
    "            ax.legend(fontsize = 9)\n",
    "\n",
    "        ax.set_xlabel(f'{featureName} (%)', fontsize = 9)\n",
    "        ax.set_ylabel(f'{name} in $\\Delta$%', fontsize = 9)\n",
    "        ax.set_xlim(0, 8)\n",
    "        if title:\n",
    "            if i == 0:\n",
    "                ax.set_title(f'Effects of {featureName.lower()} on low flow', fontsize = 9)\n",
    "            else:\n",
    "                ax.set_title(f'Effects of {featureName.lower()} on high flow', fontsize = 9)\n",
    "        ax.tick_params(labelsize=9)\n",
    "\n",
    "def plot_scatter_shap_aridity(ax1, ax2, df_Qmin7_ave, df_Qmax7_ave, title = False):\n",
    "    sns.scatterplot(df_Qmin7_ave, x = 'aridity', y = feature+'_shap', ax = ax1)\n",
    "    sns.scatterplot(df_Qmax7_ave, x = 'aridity', y = feature+'_shap', ax = ax2)\n",
    "\n",
    "    ax1.set_xlabel('Catchment aridity', fontsize = 9)\n",
    "    ax2.set_xlabel('Catchment aridity', fontsize = 9)\n",
    "\n",
    "    ax1.set_ylabel('Absolute SHAP values', fontsize = 9)\n",
    "    ax2.set_ylabel('Absolute SHAP values', fontsize = 9)\n",
    "\n",
    "    ax1.tick_params(labelsize=9)\n",
    "    ax2.tick_params(labelsize=9)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fig, axes = plt.subplots(2, 3, figsize = (10, 6))\n",
    "    plt.subplots_adjust(wspace = .3, hspace = .25)\n",
    "    \n",
    "    plot_ale(axes[0,0], axes[1,0], cfg_Qmin7, cfg_Qmax7)\n",
    "    \n",
    "    plot_shap_dependence(axes[0,1], \n",
    "                         axes[1,1], \n",
    "                         df_Qmin7.iloc[np.random.choice(df_Qmin7.shape[0], 10000),:], \n",
    "                         df_Qmax7.iloc[np.random.choice(df_Qmax7.shape[0], 10000),:]\n",
    "                        )\n",
    "    \n",
    "    plot_scatter_shap_aridity(axes[0,2], axes[1,2], df_Qmin7_ave, df_Qmax7_ave)\n",
    "\n",
    "    ax1 = inset_axes(\n",
    "        axes[1,0],\n",
    "        width = \"140%\",\n",
    "        height = \"130%\",\n",
    "        loc='lower left',\n",
    "        axes_class=GeoAxes,\n",
    "        bbox_transform=axes[1,0].transAxes,\n",
    "        axes_kwargs=dict(projection=ccrs.EqualEarth()),\n",
    "        bbox_to_anchor=(-.3, -1.9, 1.5, 1.5),\n",
    "    )\n",
    "    ax1.set_facecolor('none')\n",
    "    ax2 = ax1.inset_axes([.9, 0, 1, 1], projection =  ccrs.EqualEarth())\n",
    "    ax2.set_facecolor('none')\n",
    "\n",
    "    plot_shap_rank(ax1, ax2, df_Qmin7_ave, df_Qmax7_ave, title = True)\n",
    "    \n",
    "    import string\n",
    "    for i,ax in axes[:2,:].ravel(order='F'):\n",
    "        ax.text(-.1, 1, string.ascii_letters[i], weight = 'bold', transform = ax.transAxes, fontsize = 10)\n",
    "    \n",
    "    ax1.text(0, 1.1, 'g', weight = 'bold', transform = ax.transAxes, fontsize = 10)\n",
    "    ax2.text(0, 1.1, 'h', weight = 'bold', transform = ax.transAxes, fontsize = 10)\n",
    "    \n",
    "    fig.savefig(dir_Qmax7 / 'fig1.png', dpi = 600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e02caae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
